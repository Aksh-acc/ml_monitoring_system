{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51d3c4a-d9e9-453c-ac07-b1f7355c8518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91966\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ fc1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ fc2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ fc1 (\u001b[38;5;33mDense\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â”‚            \u001b[38;5;34m50\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ fc2 (\u001b[38;5;33mDense\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â”‚           \u001b[38;5;34m110\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output (\u001b[38;5;33mDense\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              â”‚            \u001b[38;5;34m33\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">193</span> (772.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m193\u001b[0m (772.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">193</span> (772.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m193\u001b[0m (772.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 0.2849 - mae: 0.4832 - mse: 0.2849 - val_loss: 0.2700 - val_mae: 0.4750 - val_mse: 0.2700\n",
      "Epoch 2/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.2842 - mae: 0.4847 - mse: 0.2842 - val_loss: 0.2564 - val_mae: 0.4640 - val_mse: 0.2564\n",
      "Epoch 3/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2620 - mae: 0.4672 - mse: 0.2620 - val_loss: 0.2428 - val_mae: 0.4511 - val_mse: 0.2428\n",
      "Epoch 4/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.2540 - mae: 0.4603 - mse: 0.2540 - val_loss: 0.2319 - val_mae: 0.4395 - val_mse: 0.2319\n",
      "Epoch 5/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2497 - mae: 0.4558 - mse: 0.2497 - val_loss: 0.2245 - val_mae: 0.4313 - val_mse: 0.2245\n",
      "Epoch 6/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2422 - mae: 0.4484 - mse: 0.2422 - val_loss: 0.2187 - val_mae: 0.4262 - val_mse: 0.2187\n",
      "Epoch 7/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.2422 - mae: 0.4495 - mse: 0.2422 - val_loss: 0.2154 - val_mae: 0.4252 - val_mse: 0.2154\n",
      "Epoch 8/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.2250 - mae: 0.4354 - mse: 0.2250 - val_loss: 0.2126 - val_mae: 0.4252 - val_mse: 0.2126\n",
      "Epoch 9/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.2323 - mae: 0.4459 - mse: 0.2323 - val_loss: 0.2098 - val_mae: 0.4250 - val_mse: 0.2098\n",
      "Epoch 10/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2205 - mae: 0.4365 - mse: 0.2205 - val_loss: 0.2057 - val_mae: 0.4223 - val_mse: 0.2057\n",
      "Epoch 11/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2106 - mae: 0.4274 - mse: 0.2106 - val_loss: 0.1998 - val_mae: 0.4165 - val_mse: 0.1998\n",
      "Epoch 12/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.2035 - mae: 0.4207 - mse: 0.2035 - val_loss: 0.1939 - val_mae: 0.4105 - val_mse: 0.1939\n",
      "Epoch 13/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1953 - mae: 0.4123 - mse: 0.1953 - val_loss: 0.1903 - val_mae: 0.4069 - val_mse: 0.1903\n",
      "Epoch 14/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1917 - mae: 0.4088 - mse: 0.1917 - val_loss: 0.1878 - val_mae: 0.4048 - val_mse: 0.1878\n",
      "Epoch 15/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1854 - mae: 0.4025 - mse: 0.1854 - val_loss: 0.1847 - val_mae: 0.4013 - val_mse: 0.1847\n",
      "Epoch 16/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1792 - mae: 0.3954 - mse: 0.1792 - val_loss: 0.1817 - val_mae: 0.3977 - val_mse: 0.1817\n",
      "Epoch 17/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1746 - mae: 0.3897 - mse: 0.1746 - val_loss: 0.1793 - val_mae: 0.3946 - val_mse: 0.1793\n",
      "Epoch 18/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1709 - mae: 0.3850 - mse: 0.1709 - val_loss: 0.1780 - val_mae: 0.3926 - val_mse: 0.1780\n",
      "Epoch 19/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.1662 - mae: 0.3790 - mse: 0.1662 - val_loss: 0.1772 - val_mae: 0.3911 - val_mse: 0.1772\n",
      "Epoch 20/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1633 - mae: 0.3749 - mse: 0.1633 - val_loss: 0.1751 - val_mae: 0.3880 - val_mse: 0.1751\n",
      "Epoch 21/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1613 - mae: 0.3718 - mse: 0.1613 - val_loss: 0.1725 - val_mae: 0.3844 - val_mse: 0.1725\n",
      "Epoch 22/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1532 - mae: 0.3614 - mse: 0.1532 - val_loss: 0.1702 - val_mae: 0.3808 - val_mse: 0.1702\n",
      "Epoch 23/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1544 - mae: 0.3616 - mse: 0.1544 - val_loss: 0.1669 - val_mae: 0.3761 - val_mse: 0.1669\n",
      "Epoch 24/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1485 - mae: 0.3536 - mse: 0.1485 - val_loss: 0.1633 - val_mae: 0.3712 - val_mse: 0.1633\n",
      "Epoch 25/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1504 - mae: 0.3555 - mse: 0.1504 - val_loss: 0.1596 - val_mae: 0.3661 - val_mse: 0.1596\n",
      "Epoch 26/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1425 - mae: 0.3443 - mse: 0.1425 - val_loss: 0.1561 - val_mae: 0.3611 - val_mse: 0.1561\n",
      "Epoch 27/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1378 - mae: 0.3372 - mse: 0.1378 - val_loss: 0.1532 - val_mae: 0.3568 - val_mse: 0.1532\n",
      "Epoch 28/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1395 - mae: 0.3386 - mse: 0.1395 - val_loss: 0.1511 - val_mae: 0.3531 - val_mse: 0.1511\n",
      "Epoch 29/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1318 - mae: 0.3275 - mse: 0.1318 - val_loss: 0.1488 - val_mae: 0.3493 - val_mse: 0.1488\n",
      "Epoch 30/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1330 - mae: 0.3283 - mse: 0.1330 - val_loss: 0.1465 - val_mae: 0.3455 - val_mse: 0.1465\n",
      "Epoch 31/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1264 - mae: 0.3191 - mse: 0.1264 - val_loss: 0.1454 - val_mae: 0.3429 - val_mse: 0.1454\n",
      "Epoch 32/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1226 - mae: 0.3133 - mse: 0.1226 - val_loss: 0.1436 - val_mae: 0.3395 - val_mse: 0.1436\n",
      "Epoch 33/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1248 - mae: 0.3147 - mse: 0.1248 - val_loss: 0.1408 - val_mae: 0.3353 - val_mse: 0.1408\n",
      "Epoch 34/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1198 - mae: 0.3078 - mse: 0.1198 - val_loss: 0.1378 - val_mae: 0.3309 - val_mse: 0.1378\n",
      "Epoch 35/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1172 - mae: 0.3034 - mse: 0.1172 - val_loss: 0.1333 - val_mae: 0.3252 - val_mse: 0.1333\n",
      "Epoch 36/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1151 - mae: 0.3005 - mse: 0.1151 - val_loss: 0.1298 - val_mae: 0.3206 - val_mse: 0.1298\n",
      "Epoch 37/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1178 - mae: 0.3030 - mse: 0.1178 - val_loss: 0.1286 - val_mae: 0.3181 - val_mse: 0.1286\n",
      "Epoch 38/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1114 - mae: 0.2932 - mse: 0.1114 - val_loss: 0.1282 - val_mae: 0.3161 - val_mse: 0.1282\n",
      "Epoch 39/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1085 - mae: 0.2882 - mse: 0.1085 - val_loss: 0.1273 - val_mae: 0.3133 - val_mse: 0.1273\n",
      "Epoch 40/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1072 - mae: 0.2851 - mse: 0.1072 - val_loss: 0.1255 - val_mae: 0.3094 - val_mse: 0.1255\n",
      "Epoch 41/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1080 - mae: 0.2853 - mse: 0.1080 - val_loss: 0.1220 - val_mae: 0.3042 - val_mse: 0.1220\n",
      "Epoch 42/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.1016 - mae: 0.2760 - mse: 0.1016 - val_loss: 0.1204 - val_mae: 0.3008 - val_mse: 0.1204\n",
      "Epoch 43/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0986 - mae: 0.2700 - mse: 0.0986 - val_loss: 0.1159 - val_mae: 0.2951 - val_mse: 0.1159\n",
      "Epoch 44/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1006 - mae: 0.2723 - mse: 0.1006 - val_loss: 0.1148 - val_mae: 0.2926 - val_mse: 0.1148\n",
      "Epoch 45/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1035 - mae: 0.2757 - mse: 0.1035 - val_loss: 0.1147 - val_mae: 0.2909 - val_mse: 0.1147\n",
      "Epoch 46/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1001 - mae: 0.2695 - mse: 0.1001 - val_loss: 0.1134 - val_mae: 0.2881 - val_mse: 0.1134\n",
      "Epoch 47/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0925 - mae: 0.2579 - mse: 0.0925 - val_loss: 0.1126 - val_mae: 0.2856 - val_mse: 0.1126\n",
      "Epoch 48/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0932 - mae: 0.2578 - mse: 0.0932 - val_loss: 0.1084 - val_mae: 0.2803 - val_mse: 0.1084\n",
      "Epoch 49/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0898 - mae: 0.2528 - mse: 0.0898 - val_loss: 0.1050 - val_mae: 0.2757 - val_mse: 0.1050\n",
      "Epoch 50/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0887 - mae: 0.2497 - mse: 0.0887 - val_loss: 0.1013 - val_mae: 0.2709 - val_mse: 0.1013\n",
      "Epoch 51/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0860 - mae: 0.2453 - mse: 0.0860 - val_loss: 0.0987 - val_mae: 0.2670 - val_mse: 0.0987\n",
      "Epoch 52/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0908 - mae: 0.2527 - mse: 0.0908 - val_loss: 0.0980 - val_mae: 0.2647 - val_mse: 0.0980\n",
      "Epoch 53/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0852 - mae: 0.2449 - mse: 0.0852 - val_loss: 0.0965 - val_mae: 0.2618 - val_mse: 0.0965\n",
      "Epoch 54/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0812 - mae: 0.2370 - mse: 0.0812 - val_loss: 0.0967 - val_mae: 0.2603 - val_mse: 0.0967\n",
      "Epoch 55/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0797 - mae: 0.2344 - mse: 0.0797 - val_loss: 0.0942 - val_mae: 0.2565 - val_mse: 0.0942\n",
      "Epoch 56/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0770 - mae: 0.2293 - mse: 0.0770 - val_loss: 0.0911 - val_mae: 0.2521 - val_mse: 0.0911\n",
      "Epoch 57/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0816 - mae: 0.2370 - mse: 0.0816 - val_loss: 0.0880 - val_mae: 0.2478 - val_mse: 0.0880\n",
      "Epoch 58/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0737 - mae: 0.2234 - mse: 0.0737 - val_loss: 0.0872 - val_mae: 0.2454 - val_mse: 0.0872\n",
      "Epoch 59/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0728 - mae: 0.2227 - mse: 0.0728 - val_loss: 0.0862 - val_mae: 0.2429 - val_mse: 0.0862\n",
      "Epoch 60/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0740 - mae: 0.2222 - mse: 0.0740 - val_loss: 0.0866 - val_mae: 0.2415 - val_mse: 0.0866\n",
      "Epoch 61/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0728 - mae: 0.2197 - mse: 0.0728 - val_loss: 0.0858 - val_mae: 0.2390 - val_mse: 0.0858\n",
      "Epoch 62/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0723 - mae: 0.2178 - mse: 0.0723 - val_loss: 0.0835 - val_mae: 0.2354 - val_mse: 0.0835\n",
      "Epoch 63/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0711 - mae: 0.2164 - mse: 0.0711 - val_loss: 0.0786 - val_mae: 0.2295 - val_mse: 0.0786\n",
      "Epoch 64/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0739 - mae: 0.2205 - mse: 0.0739 - val_loss: 0.0782 - val_mae: 0.2276 - val_mse: 0.0782\n",
      "Epoch 65/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0646 - mae: 0.2050 - mse: 0.0646 - val_loss: 0.0812 - val_mae: 0.2286 - val_mse: 0.0812\n",
      "Epoch 66/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0665 - mae: 0.2072 - mse: 0.0665 - val_loss: 0.0813 - val_mae: 0.2273 - val_mse: 0.0813\n",
      "Epoch 67/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0656 - mae: 0.2038 - mse: 0.0656 - val_loss: 0.0764 - val_mae: 0.2216 - val_mse: 0.0764\n",
      "Epoch 68/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0646 - mae: 0.2036 - mse: 0.0646 - val_loss: 0.0699 - val_mae: 0.2143 - val_mse: 0.0699\n",
      "Epoch 69/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0656 - mae: 0.2033 - mse: 0.0656 - val_loss: 0.0676 - val_mae: 0.2107 - val_mse: 0.0676\n",
      "Epoch 70/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0626 - mae: 0.1988 - mse: 0.0626 - val_loss: 0.0699 - val_mae: 0.2114 - val_mse: 0.0699\n",
      "Epoch 71/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0613 - mae: 0.1968 - mse: 0.0613 - val_loss: 0.0733 - val_mae: 0.2129 - val_mse: 0.0733\n",
      "Epoch 72/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0578 - mae: 0.1885 - mse: 0.0578 - val_loss: 0.0756 - val_mae: 0.2134 - val_mse: 0.0756\n",
      "Epoch 73/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0612 - mae: 0.1932 - mse: 0.0612 - val_loss: 0.0699 - val_mae: 0.2070 - val_mse: 0.0699\n",
      "Epoch 74/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0563 - mae: 0.1863 - mse: 0.0563 - val_loss: 0.0669 - val_mae: 0.2030 - val_mse: 0.0669\n",
      "Epoch 75/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0509 - mae: 0.1768 - mse: 0.0509 - val_loss: 0.0665 - val_mae: 0.2012 - val_mse: 0.0665\n",
      "Epoch 76/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0545 - mae: 0.1819 - mse: 0.0545 - val_loss: 0.0615 - val_mae: 0.1952 - val_mse: 0.0615\n",
      "Epoch 77/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0547 - mae: 0.1832 - mse: 0.0547 - val_loss: 0.0602 - val_mae: 0.1927 - val_mse: 0.0602\n",
      "Epoch 78/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0493 - mae: 0.1721 - mse: 0.0493 - val_loss: 0.0625 - val_mae: 0.1935 - val_mse: 0.0625\n",
      "Epoch 79/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0530 - mae: 0.1764 - mse: 0.0530 - val_loss: 0.0620 - val_mae: 0.1916 - val_mse: 0.0620\n",
      "Epoch 80/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0532 - mae: 0.1782 - mse: 0.0532 - val_loss: 0.0596 - val_mae: 0.1880 - val_mse: 0.0596\n",
      "Epoch 81/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0518 - mae: 0.1741 - mse: 0.0518 - val_loss: 0.0572 - val_mae: 0.1844 - val_mse: 0.0572\n",
      "Epoch 82/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0482 - mae: 0.1711 - mse: 0.0482 - val_loss: 0.0575 - val_mae: 0.1835 - val_mse: 0.0575\n",
      "Epoch 83/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0525 - mae: 0.1761 - mse: 0.0525 - val_loss: 0.0573 - val_mae: 0.1821 - val_mse: 0.0573\n",
      "Epoch 84/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0491 - mae: 0.1692 - mse: 0.0491 - val_loss: 0.0578 - val_mae: 0.1813 - val_mse: 0.0578\n",
      "Epoch 85/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0462 - mae: 0.1616 - mse: 0.0462 - val_loss: 0.0589 - val_mae: 0.1812 - val_mse: 0.0589\n",
      "Epoch 86/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0434 - mae: 0.1578 - mse: 0.0434 - val_loss: 0.0572 - val_mae: 0.1784 - val_mse: 0.0572\n",
      "Epoch 87/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0491 - mae: 0.1661 - mse: 0.0491 - val_loss: 0.0536 - val_mae: 0.1737 - val_mse: 0.0536\n",
      "Epoch 88/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0448 - mae: 0.1604 - mse: 0.0448 - val_loss: 0.0518 - val_mae: 0.1708 - val_mse: 0.0518\n",
      "Epoch 89/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0454 - mae: 0.1601 - mse: 0.0454 - val_loss: 0.0525 - val_mae: 0.1703 - val_mse: 0.0525\n",
      "Epoch 90/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0453 - mae: 0.1599 - mse: 0.0453 - val_loss: 0.0509 - val_mae: 0.1676 - val_mse: 0.0509\n",
      "Epoch 91/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0449 - mae: 0.1570 - mse: 0.0449 - val_loss: 0.0526 - val_mae: 0.1682 - val_mse: 0.0526\n",
      "Epoch 92/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0373 - mae: 0.1445 - mse: 0.0373 - val_loss: 0.0577 - val_mae: 0.1720 - val_mse: 0.0577\n",
      "Epoch 93/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0399 - mae: 0.1466 - mse: 0.0399 - val_loss: 0.0568 - val_mae: 0.1702 - val_mse: 0.0568\n",
      "Epoch 94/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0421 - mae: 0.1495 - mse: 0.0421 - val_loss: 0.0491 - val_mae: 0.1614 - val_mse: 0.0491\n",
      "Epoch 95/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0359 - mae: 0.1411 - mse: 0.0359 - val_loss: 0.0469 - val_mae: 0.1581 - val_mse: 0.0469\n",
      "Epoch 96/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0397 - mae: 0.1465 - mse: 0.0397 - val_loss: 0.0440 - val_mae: 0.1540 - val_mse: 0.0440\n",
      "Epoch 97/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0366 - mae: 0.1398 - mse: 0.0366 - val_loss: 0.0464 - val_mae: 0.1555 - val_mse: 0.0464\n",
      "Epoch 98/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0393 - mae: 0.1443 - mse: 0.0393 - val_loss: 0.0494 - val_mae: 0.1577 - val_mse: 0.0494\n",
      "Epoch 99/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0366 - mae: 0.1401 - mse: 0.0366 - val_loss: 0.0458 - val_mae: 0.1529 - val_mse: 0.0458\n",
      "Epoch 100/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0357 - mae: 0.1387 - mse: 0.0357 - val_loss: 0.0427 - val_mae: 0.1486 - val_mse: 0.0427\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0490 - mae: 0.1468 - mse: 0.0490\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from prometheus_client import CollectorRegistry, Gauge, push_to_gateway\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# âœ… Log Configuration\n",
    "LOG_FILE = \"C:/Users/91966/ml_monitor/logs/ml_model.log\"\n",
    "logging.basicConfig(filename=LOG_FILE, level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "def log_event(level, message):\n",
    "    \"\"\"Logs an event in JSON format.\"\"\"\n",
    "    log_entry = {\"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), \"level\": level, \"message\": message}\n",
    "    with open(LOG_FILE, \"a\") as f:\n",
    "        f.write(json.dumps(log_entry) + \"\\n\")\n",
    "    logging.info(message) if level.lower() == \"info\" else logging.error(message)\n",
    "\n",
    "# âœ… Load Iris Dataset\n",
    "iris_data = load_iris()\n",
    "df = pd.DataFrame(iris_data['data'], columns=iris_data['feature_names'])\n",
    "\n",
    "# âœ… Encode Labels & Train-Test Split\n",
    "x = iris_data['data']\n",
    "y_ = iris_data['target'].reshape(-1, 1)  \n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y = encoder.fit_transform(y_)\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.20)\n",
    "\n",
    "# âœ… Define Model\n",
    "model = Sequential([\n",
    "    Dense(10, input_shape=(4,), activation='relu', name='fc1'),\n",
    "    Dense(10, activation='relu', name='fc2'),\n",
    "    Dense(3, activation='softmax', name='output')\n",
    "])\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mse', 'mae'])\n",
    "print(model.summary())\n",
    "\n",
    "# âœ… Train Model with Logging Callback\n",
    "class LoggingCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        log_event(\"info\", f\"Epoch {epoch+1}: Loss={logs['loss']:.4f}, Val_Loss={logs.get('val_loss', 0):.4f}, MAE={logs['mae']:.4f}\")\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
    "history = model.fit(train_x, train_y, epochs=100, verbose=1, validation_split=0.1, callbacks=[early_stop, LoggingCallback()])\n",
    "\n",
    "# âœ… Log Training Results\n",
    "hist = history.history\n",
    "rmse_final = np.sqrt(float(hist['val_mse'][-1]))\n",
    "log_event(\"info\", f\"Final RMSE on validation set: {rmse_final:.4f}\")\n",
    "\n",
    "# âœ… Evaluate Model\n",
    "mse, mae, _ = model.evaluate(test_x, test_y)\n",
    "rmse = np.sqrt(mse)\n",
    "# log_event(\"info\", f\"Test Evaluation -> RMSE: {rmse:.4f}, MAE: {mae:.4f} , Z_Score = {z_scores} , Mean_Value = {mean_value}\")\n",
    "\n",
    "# âœ… Prometheus Metrics Setup\n",
    "registry = CollectorRegistry()\n",
    "n_rmse_gauge = Gauge(\"n_rmse\", \"Root Mean Squared Error\", registry=registry)\n",
    "accuracy_gauge = Gauge(\"accuracy\", \"Model Accuracy\", registry=registry)\n",
    "mean_metric = Gauge('feature_x_mean', 'Mean of feature_x', ['feature'], registry=registry)\n",
    "stddev_metric = Gauge('feature_x_stddev', 'Standard Deviation of feature_x', ['feature'], registry=registry)\n",
    "outlier_metric = Gauge('feature_x_outliers', 'Percentage of outliers in feature_x', ['feature'], registry=registry)\n",
    "class_distribution = Gauge('class_distribution', 'Distribution of classes', ['species'], registry=registry)\n",
    "\n",
    "# âœ… Compute Feature Statistics\n",
    "\n",
    "# âœ… Send Metrics to Prometheus Pushgateway\n",
    "try:\n",
    "    push_to_gateway(\"localhost:9091\", job=\"model_metrics\", registry=registry)\n",
    "    log_event(\"info\", \"ğŸ“¡ Feature drift metrics pushed to Prometheus!\")\n",
    "except Exception as e:\n",
    "    log_event(\"error\", f\"âš ï¸ Error pushing metrics: {e}\")\n",
    "\n",
    "# âœ… Real-Time Monitoring & Logging\n",
    "num = np.shape(test_y)[0]\n",
    "push_interval = 10  \n",
    "last_push = time.time()\n",
    "\n",
    "for i in range(100000):  \n",
    "    indx = random.randint(0, num - 1)  \n",
    "    x_batch = np.expand_dims(test_x[indx, :], axis=0)\n",
    "    y_batch = np.expand_dims(test_y[indx], axis=0)\n",
    "    mse, mae, _ = model.evaluate(x_batch, y_batch, verbose=0)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # âœ… Log real-time prediction performance\n",
    "\n",
    "    # âœ… Push Metrics to Prometheus\n",
    "    n_rmse_gauge.set(rmse)\n",
    "    accuracy_gauge.set(1 / (1 + rmse)) \n",
    "\n",
    "    feature_stats = {}\n",
    "    for feature in df.columns:\n",
    "        mean_value = df[feature].mean()\n",
    "        stddev_value = df[feature].std()\n",
    "        z_scores = (df[feature] - mean_value) / stddev_value\n",
    "        outlier_percentage = (np.abs(z_scores) > 3).sum() / len(df) * 100  \n",
    "        feature_stats[feature] = {\"mean\": mean_value, \"stddev\": stddev_value, \"outliers\": outlier_percentage}\n",
    "\n",
    "    # âœ… Compute Class Distribution\n",
    "    species_labels = iris_data[\"target\"]\n",
    "    class_counts = pd.Series(species_labels).value_counts(normalize=True) * 100  # % Distribution\n",
    "    \n",
    "    log_event(\"info\", f\"Iteration {i}: RMSE={rmse:.4f}, MAE={mae:.4f} , Z_Score = {z_scores} , Mean_Value = {mean_value}\")\n",
    "    # âœ… Push Feature Metrics\n",
    "    for feature, stats in feature_stats.items():\n",
    "        mean_metric.labels(feature=feature).set(stats[\"mean\"])\n",
    "        stddev_metric.labels(feature=feature).set(stats[\"stddev\"])\n",
    "        outlier_metric.labels(feature=feature).set(stats[\"outliers\"])\n",
    "\n",
    "    # âœ… Push Class Distribution\n",
    "    for species, percentage in class_counts.items():\n",
    "        class_distribution.labels(species=iris_data[\"target_names\"][species]).set(percentage)\n",
    "\n",
    "    current_time = time.time()\n",
    "    if current_time - last_push >= push_interval:\n",
    "        try:\n",
    "            push_to_gateway(\"localhost:9091\", job=\"model_metrics\", registry=registry)\n",
    "            log_event(\"info\", f\"Metrics pushed at iteration {i}. RMSE={rmse:.4f}, MAE={mae:.4f} , Z_Score = {z_scores} , Mean_Value = {mean_value}\")\n",
    "            last_push = current_time\n",
    "        except Exception as e:\n",
    "            log_event(\"error\", f\"Error pushing metrics: {str(e)}\")\n",
    "\n",
    "    time.sleep(0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "48213070-e92c-4a6e-999d-b338b602f70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.2\n",
       "1      0.2\n",
       "2      0.2\n",
       "3      0.2\n",
       "4      0.2\n",
       "      ... \n",
       "145    2.3\n",
       "146    1.9\n",
       "147    2.0\n",
       "148    2.3\n",
       "149    1.8\n",
       "Name: petal width (cm), Length: 150, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iris_data = load_iris()\n",
    "\n",
    "# # âœ… Convert to Pandas DataFrame\n",
    "# df = pd.DataFrame(iris_data['data'], columns=iris_data['feature_names'])\n",
    "\n",
    "# # âœ… Print first few rows to verify\n",
    "# print(df.head())\n",
    "# print(df.columns[0])\n",
    "\n",
    "df[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c409dab3-835a-4025-830f-7869140720d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ” Column Names in Dataset:\", iris_data.keys())\n",
    "print(iris_data['feature_names'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
